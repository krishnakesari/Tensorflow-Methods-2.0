{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from jinja2 import optimizer\n",
    "from tensorflow import keras\n",
    "from keras_preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters in the book:  456649\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(char_level=True)\n",
    "file_name = './paradise_lost.txt'\n",
    "text_1 = open(file_name, 'r').read().lower()\n",
    "print('Total number of characters in the book: ', len(text_1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40 unique characters. \n",
      "Char to integer dictionary:  {' ': 1, 'e': 2, 't': 3, 'o': 4, 'a': 5, 'h': 6, 'n': 7, 'i': 8, 's': 9, 'r': 10, 'd': 11, 'l': 12, '\\n': 13, 'u': 14, ',': 15, 'm': 16, 'f': 17, 'w': 18, 'g': 19, 'c': 20, 'p': 21, 'b': 22, 'y': 23, 'v': 24, '’': 25, '_': 26, 'k': 27, ';': 28, '.': 29, ':': 30, 'j': 31, 'x': 32, '?': 33, 'q': 34, '-': 35, 'z': 36, '&': 37, '(': 38, ')': 39, '!': 40}\n",
      "Integer to char dictionary:  {0: ' ', 1: 'e', 2: 't', 3: 'o', 4: 'a', 5: 'h', 6: 'n', 7: 'i', 8: 's', 9: 'r', 10: 'd', 11: 'l', 12: '\\n', 13: 'u', 14: ',', 15: 'm', 16: 'f', 17: 'w', 18: 'g', 19: 'c', 20: 'p', 21: 'b', 22: 'y', 23: 'v', 24: '’', 25: '_', 26: 'k', 27: ';', 28: '.', 29: ':', 30: 'j', 31: 'x', 32: '?', 33: 'q', 34: '-', 35: 'z', 36: '&', 37: '(', 38: ')', 39: '!'}\n"
     ]
    }
   ],
   "source": [
    "# Create mapping between unique characters to integers and reverse \n",
    "tokenizer.fit_on_texts(text_1)\n",
    "char_index = tokenizer.word_index\n",
    "print('Found %s unique characters. ' % len(char_index))\n",
    "print('Char to integer dictionary: ', char_index)\n",
    "\n",
    "index_char = dict(enumerate(char_index.keys()))\n",
    "print('Integer to char dictionary: ', index_char)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of patterns 456644\n",
      "[[1, 21, 5, 10, 5], [21, 5, 10, 5, 11], [5, 10, 5, 11, 8], [10, 5, 11, 8, 9], [5, 11, 8, 9, 2], [11, 8, 9, 2, 1], [8, 9, 2, 1, 12], [9, 2, 1, 12, 4], [2, 1, 12, 4, 9], [1, 12, 4, 9, 3]]\n",
      "[11, 8, 9, 2, 1, 12, 4, 9, 3, 13]\n"
     ]
    }
   ],
   "source": [
    "# Creating input Tensor and Output Vectors\n",
    "char_len = len(text_1)\n",
    "seq_lenth = 5\n",
    "data_X = []\n",
    "data_y = []\n",
    "for i in range(0, char_len - seq_lenth, 1):\n",
    "    input_seq = text_1[i:i + seq_lenth]\n",
    "    output_seq = text_1[i + seq_lenth]\n",
    "    data_X.append([char_index[char] for char in input_seq])\n",
    "    data_y.append(char_index[output_seq])\n",
    "n_patterns = len(data_X)\n",
    "print('Total number of patterns', n_patterns)\n",
    "\n",
    "# Print first 10 elements in data_X\n",
    "print(data_X[:10])\n",
    "print(data_y[:10])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.025]\n",
      "  [0.525]\n",
      "  [0.125]\n",
      "  [0.25 ]\n",
      "  [0.125]]\n",
      "\n",
      " [[0.525]\n",
      "  [0.125]\n",
      "  [0.25 ]\n",
      "  [0.125]\n",
      "  [0.275]]\n",
      "\n",
      " [[0.125]\n",
      "  [0.25 ]\n",
      "  [0.125]\n",
      "  [0.275]\n",
      "  [0.2  ]]]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Reshaping data - to create numpy arrays\n",
    "X = np.reshape(data_X, (n_patterns, seq_lenth, 1))\n",
    "# Normalizing data - by dividing each element of the array by the number of unique characters in the book\n",
    "X = X / len(char_index)\n",
    "# One-hot encoding for y vector\n",
    "y = keras.utils.to_categorical(data_y)\n",
    "## Printing first 3 elements\n",
    "print(X[:3])\n",
    "print(y[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : (456644, 5, 1)\n",
      "Shape of first element:  5\n",
      "Shape of second element:  1\n"
     ]
    }
   ],
   "source": [
    "print('Shape of X :', X.shape)\n",
    "print('Shape of first element: ', X.shape[1])\n",
    "print('Shape of second element: ', X.shape[2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 13:10:34.692307: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-13 13:10:34.693446: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 256)               264192    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 41)                10537     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 274,729\n",
      "Trainable params: 274,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Building Recurrent Neural Networks using LSTM (GRU can be used as a substitute for LSTM)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.LSTM((256), return_sequences=False, input_shape=(X.shape[1], X.shape[2])),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(y.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 13:19:55.457616: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-13 13:19:55.903727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-13 13:19:56.103746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-02-13 13:19:57.591248: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3568/3568 [==============================] - ETA: 0s - loss: 2.9067\n",
      "Epoch 00001: loss improved from inf to 2.90667, saving model to weights-improvement-1-2.9067.hdf5\n",
      "3568/3568 [==============================] - 48s 13ms/step - loss: 2.9067\n",
      "Epoch 2/30\n",
      "3565/3568 [============================>.] - ETA: 0s - loss: 2.7750\n",
      "Epoch 00002: loss improved from 2.90667 to 2.77500, saving model to weights-improvement-2-2.7750.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 2.7750\n",
      "Epoch 3/30\n",
      "3564/3568 [============================>.] - ETA: 0s - loss: 2.7141\n",
      "Epoch 00003: loss improved from 2.77500 to 2.71400, saving model to weights-improvement-3-2.7140.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 2.7140\n",
      "Epoch 4/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 2.6590\n",
      "Epoch 00004: loss improved from 2.71400 to 2.65903, saving model to weights-improvement-4-2.6590.hdf5\n",
      "3568/3568 [==============================] - 44s 12ms/step - loss: 2.6590\n",
      "Epoch 5/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 2.6084\n",
      "Epoch 00005: loss improved from 2.65903 to 2.60842, saving model to weights-improvement-5-2.6084.hdf5\n",
      "3568/3568 [==============================] - 44s 12ms/step - loss: 2.6084\n",
      "Epoch 6/30\n",
      "3565/3568 [============================>.] - ETA: 0s - loss: 2.5539\n",
      "Epoch 00006: loss improved from 2.60842 to 2.55391, saving model to weights-improvement-6-2.5539.hdf5\n",
      "3568/3568 [==============================] - 44s 12ms/step - loss: 2.5539\n",
      "Epoch 7/30\n",
      "3565/3568 [============================>.] - ETA: 0s - loss: 2.4881\n",
      "Epoch 00007: loss improved from 2.55391 to 2.48816, saving model to weights-improvement-7-2.4882.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 2.4882\n",
      "Epoch 8/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 2.4108\n",
      "Epoch 00008: loss improved from 2.48816 to 2.41076, saving model to weights-improvement-8-2.4108.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 2.4108\n",
      "Epoch 9/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 2.3249\n",
      "Epoch 00009: loss improved from 2.41076 to 2.32491, saving model to weights-improvement-9-2.3249.hdf5\n",
      "3568/3568 [==============================] - 47s 13ms/step - loss: 2.3249\n",
      "Epoch 10/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 2.2416\n",
      "Epoch 00010: loss improved from 2.32491 to 2.24156, saving model to weights-improvement-10-2.2416.hdf5\n",
      "3568/3568 [==============================] - 48s 13ms/step - loss: 2.2416\n",
      "Epoch 11/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 2.1712\n",
      "Epoch 00011: loss improved from 2.24156 to 2.17122, saving model to weights-improvement-11-2.1712.hdf5\n",
      "3568/3568 [==============================] - 46s 13ms/step - loss: 2.1712\n",
      "Epoch 12/30\n",
      "3564/3568 [============================>.] - ETA: 0s - loss: 2.1109\n",
      "Epoch 00012: loss improved from 2.17122 to 2.11088, saving model to weights-improvement-12-2.1109.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 2.1109\n",
      "Epoch 13/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 2.0520\n",
      "Epoch 00013: loss improved from 2.11088 to 2.05204, saving model to weights-improvement-13-2.0520.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 2.0520\n",
      "Epoch 14/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 2.0088\n",
      "Epoch 00014: loss improved from 2.05204 to 2.00882, saving model to weights-improvement-14-2.0088.hdf5\n",
      "3568/3568 [==============================] - 46s 13ms/step - loss: 2.0088\n",
      "Epoch 15/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.9731\n",
      "Epoch 00015: loss improved from 2.00882 to 1.97323, saving model to weights-improvement-15-1.9732.hdf5\n",
      "3568/3568 [==============================] - 47s 13ms/step - loss: 1.9732\n",
      "Epoch 16/30\n",
      "3568/3568 [==============================] - ETA: 0s - loss: 1.9449\n",
      "Epoch 00016: loss improved from 1.97323 to 1.94487, saving model to weights-improvement-16-1.9449.hdf5\n",
      "3568/3568 [==============================] - 46s 13ms/step - loss: 1.9449\n",
      "Epoch 17/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.9178\n",
      "Epoch 00017: loss improved from 1.94487 to 1.91786, saving model to weights-improvement-17-1.9179.hdf5\n",
      "3568/3568 [==============================] - 44s 12ms/step - loss: 1.9179\n",
      "Epoch 18/30\n",
      "3565/3568 [============================>.] - ETA: 0s - loss: 1.8962\n",
      "Epoch 00018: loss improved from 1.91786 to 1.89618, saving model to weights-improvement-18-1.8962.hdf5\n",
      "3568/3568 [==============================] - 44s 12ms/step - loss: 1.8962\n",
      "Epoch 19/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.8782\n",
      "Epoch 00019: loss improved from 1.89618 to 1.87820, saving model to weights-improvement-19-1.8782.hdf5\n",
      "3568/3568 [==============================] - 43s 12ms/step - loss: 1.8782\n",
      "Epoch 20/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.8593\n",
      "Epoch 00020: loss improved from 1.87820 to 1.85931, saving model to weights-improvement-20-1.8593.hdf5\n",
      "3568/3568 [==============================] - 43s 12ms/step - loss: 1.8593\n",
      "Epoch 21/30\n",
      "3565/3568 [============================>.] - ETA: 0s - loss: 1.8438\n",
      "Epoch 00021: loss improved from 1.85931 to 1.84375, saving model to weights-improvement-21-1.8438.hdf5\n",
      "3568/3568 [==============================] - 43s 12ms/step - loss: 1.8438\n",
      "Epoch 22/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 1.8277\n",
      "Epoch 00022: loss improved from 1.84375 to 1.82766, saving model to weights-improvement-22-1.8277.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 1.8277\n",
      "Epoch 23/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.8141\n",
      "Epoch 00023: loss improved from 1.82766 to 1.81414, saving model to weights-improvement-23-1.8141.hdf5\n",
      "3568/3568 [==============================] - 47s 13ms/step - loss: 1.8141\n",
      "Epoch 24/30\n",
      "3565/3568 [============================>.] - ETA: 0s - loss: 1.8026\n",
      "Epoch 00024: loss improved from 1.81414 to 1.80252, saving model to weights-improvement-24-1.8025.hdf5\n",
      "3568/3568 [==============================] - 53s 15ms/step - loss: 1.8025\n",
      "Epoch 25/30\n",
      "3565/3568 [============================>.] - ETA: 0s - loss: 1.7920\n",
      "Epoch 00025: loss improved from 1.80252 to 1.79205, saving model to weights-improvement-25-1.7921.hdf5\n",
      "3568/3568 [==============================] - 51s 14ms/step - loss: 1.7921\n",
      "Epoch 26/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.7811\n",
      "Epoch 00026: loss improved from 1.79205 to 1.78121, saving model to weights-improvement-26-1.7812.hdf5\n",
      "3568/3568 [==============================] - 46s 13ms/step - loss: 1.7812\n",
      "Epoch 27/30\n",
      "3567/3568 [============================>.] - ETA: 0s - loss: 1.7722\n",
      "Epoch 00027: loss improved from 1.78121 to 1.77221, saving model to weights-improvement-27-1.7722.hdf5\n",
      "3568/3568 [==============================] - 46s 13ms/step - loss: 1.7722\n",
      "Epoch 28/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.7628\n",
      "Epoch 00028: loss improved from 1.77221 to 1.76277, saving model to weights-improvement-28-1.7628.hdf5\n",
      "3568/3568 [==============================] - 45s 13ms/step - loss: 1.7628\n",
      "Epoch 29/30\n",
      "3566/3568 [============================>.] - ETA: 0s - loss: 1.7539\n",
      "Epoch 00029: loss improved from 1.76277 to 1.75386, saving model to weights-improvement-29-1.7539.hdf5\n",
      "3568/3568 [==============================] - 46s 13ms/step - loss: 1.7539\n",
      "Epoch 30/30\n",
      "3564/3568 [============================>.] - ETA: 0s - loss: 1.7436\n",
      "Epoch 00030: loss improved from 1.75386 to 1.74357, saving model to weights-improvement-30-1.7436.hdf5\n",
      "3568/3568 [==============================] - 46s 13ms/step - loss: 1.7436\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x16b7f64f0>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "filepath='weights-improvement-{epoch}-{loss:.4f}.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, epochs=30, batch_size=128, callbacks=callbacks_list)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Patterns : 456644\n",
      "Starting Random Number:  53\n",
      "['i', 'e', 'f', 's', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# Loading the weights file\n",
    "model.load_weights('weights-improvement-30-1.7436.hdf5')\n",
    "print('Total Number of Patterns :', len(data_X))\n",
    "\n",
    "start = np.random.randint(50, 100)\n",
    "print('Starting Random Number: ', start)\n",
    "pattern = data_X[start]\n",
    "print([''.join(index_char[value]) for value in pattern])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trraieeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtseeiofrheevbsrnftiedatm,shhitktiotepthdttdedift;shiuoyegedriuectrtse\n"
     ]
    }
   ],
   "source": [
    "# Generate Characters\n",
    "txt_fl = []\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / len(char_index)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = index_char[index].rstrip('\\n\\r')\n",
    "    seq_in = [index_char[value] for value in pattern]\n",
    "    # Print result\n",
    "    txt_fl.append(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1: len(pattern)]\n",
    "\n",
    "print(''.join(txt_fl))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}